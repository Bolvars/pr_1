{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Никита Иващенко -  7 вариант</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Задание 1</h1>\n",
    "\n",
    "На маркетплейсе есть огромный объем данных содержащий записи о продажах различных продуктов. Наша цель — рассчитать общий доход, полученный от каждого продукта за определённый период. \n",
    "\n",
    "Необходимо решить задачу через классический python, numpy и numpy с использованием векторизации\n",
    "\n",
    "\n",
    "Данные: \n",
    "products = ['автомобиль HAVAL', 'обувь', 'одежда', 'телефоны'] (при решении через numpy необходимо представить это в виде np.array() )\n",
    "prices = [20000, 3000, 45600, 5000] (при решении через numpy необходимо представить это в виде np.array() ) \n",
    "\n",
    "Данные о продажах необходимо сгенерировать самостоятельно и вывести в одном параграфов в ноутбуке, ниже приведен пример генерации случайных значений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIncomeWithVanilaPython(products:list[str],prices:list[int], sales:list[int]): \n",
    "    income = [sum(list(map(lambda x: x*p, s))) for p,s in zip(prices,sales)]\n",
    "    return {prdct:incm for prdct,incm in zip(products,income)}\n",
    "#\n",
    "\n",
    "def checkIncomeWithNumPy(products:np.ndarray, prices:np.ndarray, sales:np.ndarray) -> np.ndarray:\n",
    "    return np.array([(prdct,np.sum([prc*si for si in sls], dtype=\"f4\")) for prdct,prc,sls in zip(products,prices,sales)],\n",
    "                    dtype={\n",
    "                            \"names\": [\"products\", \"income\"],\n",
    "                            \"formats\": [\"U16\", \"f4\"]\n",
    "                            }\n",
    "                   )\n",
    "\n",
    "def checkIncomeWithVectrNumPy(products:np.ndarray, prices:np.ndarray,sales:np.ndarray) -> np.ndarray:\n",
    "    #income = sales.T * prices\n",
    "    #return np.sum(income.T, axis=1, dtype=np.float32)\n",
    "    return np.array([(prdct,np.sum(prc*sls,dtype=\"f4\")) for prdct,prc,sls in zip(products,prices,sales)],\n",
    "                    dtype={\n",
    "                            \"names\": [\"products\", \"income\"],\n",
    "                            \"formats\": [\"U16\", \"f4\"]\n",
    "                            }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = 7 # подставьте номер своего  варианта\n",
    "products = ['автомобиль HAVAL', 'обувь', 'одежда', 'телефоны']\n",
    "prices = [20000, 3000, 45600, 5000]\n",
    "sales = [[random.randint(0, variant+100) for i in range(100000)] for _ in range(len(prices))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# данные для numpy \n",
    "products_np = np.array(products)\n",
    "prices_np = np.array(prices)\n",
    "sales_np = np.array(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'автомобиль HAVAL': 106995220000,\n",
       "  'обувь': 16064586000,\n",
       "  'одежда': 243849693600,\n",
       "  'телефоны': 26744230000},\n",
       " array([('автомобиль HAVAL', 1.0699521e+11), ('обувь', 1.6064586e+10),\n",
       "        ('одежда', 2.4384967e+11), ('телефоны', 2.6744230e+10)],\n",
       "       dtype=[('products', '<U16'), ('income', '<f4')]),\n",
       " array([('автомобиль HAVAL', 1.0699521e+11), ('обувь', 1.6064586e+10),\n",
       "        ('одежда', 2.4384967e+11), ('телефоны', 2.6744230e+10)],\n",
       "       dtype=[('products', '<U16'), ('income', '<f4')]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkIncomeWithVanilaPython(products,prices,sales),checkIncomeWithNumPy(products_np,prices_np,sales_np),checkIncomeWithVectrNumPy(products_np,prices_np,sales_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.8 ms ± 299 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "31.5 ms ± 438 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "355 µs ± 8.94 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit checkIncomeWithVanilaPython(products,prices,sales)\n",
    "%timeit checkIncomeWithNumPy(products_np,prices_np,sales_np)\n",
    "%timeit checkIncomeWithVectrNumPy(products_np,prices_np,sales_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные в различных реализациях должны совпадать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После генерации необходимо сравнить доход от каждого продукта и время на выполнение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Задание 2</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо написать с использованием numpy реализацию одного из следующих алгоритмов: \n",
    "\n",
    "- heapsort (вариант: 1,5,9,13,17,21)\n",
    "\n",
    "- mergesort (вариант: 2,6,10,14,18,22)\n",
    "\n",
    "- stable (вариант: 3,7,11,15,19)\n",
    "\n",
    "- quicksort (вариант: 4,8,12,16,20) \n",
    "\n",
    "Сравнить скорость выполнения этих алгоритмов на чистом python, вашей реализации и numpy.sort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countingSort(arr:np.ndarray):\n",
    "    max_el = np.max(arr)\n",
    "    count_arr = np.array([0 for i in range(max_el+1)])\n",
    "    for i in arr:\n",
    "        count_arr[i]+=1\n",
    "    s = 0\n",
    "    for i,v in enumerate(count_arr):\n",
    "        if v != 0:\n",
    "            arr[s:s+v] = i\n",
    "            s += v\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([random.randint(0, variant+100) for i in range(1000000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 ms ± 474 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "6.11 ms ± 30.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit countingSort(arr)\n",
    "%timeit np.sort(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Задание 3</h1> \n",
    "\n",
    "У нас есть данные о потреблении алкоголя о потреблнеии Алкоголя в мире https://github.com/fivethirtyeight/data/tree/master/alcohol-consumption. \n",
    "\n",
    "Давайте представим эти данные в виде структурированных массивов и определим, где же люди пьют больше вина, пива и других спиртных напитков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"max beer_servings - ['Namibia'] = 376\",\n",
       " \"max total_litres_of_pure_alcohol - ['Belarus'] = 14.399999618530273\",\n",
       " \"max spirit_servings - ['Grenada'] = 438\",\n",
       " \"max wine_servings - ['France'] = 370\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "\n",
    "def getNpArrayFromCSV(url:str, dtype=list[tuple[str,str]]) -> np.ndarray:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = np.genfromtxt(StringIO(response.text), delimiter=',', skip_header=1, dtype=dtype)\n",
    "    return data\n",
    "\n",
    "url_alc = 'https://raw.githubusercontent.com/fivethirtyeight/data/master/alcohol-consumption/drinks.csv'\n",
    "dtype_alc = [\n",
    "        (\"country\", 'U16'),\n",
    "        (\"beer_servings\", 'i'),\n",
    "        (\"spirit_servings\", 'i'),\n",
    "        (\"wine_servings\", 'i'),\n",
    "        (\"total_litres_of_pure_alcohol\", 'f'),\n",
    "    ]\n",
    "dtAlc = getNpArrayFromCSV(url_alc, dtype = dtype_alc)\n",
    "\n",
    "def checkCountryMaxServings(column:str, data:np.ndarray):\n",
    "    return f'max {column} - {data[data[column] == np.max(data[column])][\"country\"]} = {np.max(data[column])}'\n",
    "    \n",
    "checkCountryMaxServings('beer_servings',dtAlc),checkCountryMaxServings('total_litres_of_pure_alcohol',dtAlc),checkCountryMaxServings('spirit_servings',dtAlc),checkCountryMaxServings('wine_servings',dtAlc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Задание 4</h1> \n",
    "\n",
    "У нас есть Полный каталог всех случаев, когда кто-то проклинал или истекал кровью в фильме Квентина Тарантино. https://github.com/fivethirtyeight/data/tree/master/tarantino\n",
    "\n",
    "Давайте представим эти данные в виде структурированных массивов и определим:\n",
    "\n",
    "- число проклятий, летальных исходов и их отношение по фильмам \n",
    "\n",
    "- частота употребления конкретных прокрятий \n",
    "\n",
    "- распределение времени между проклятиями "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('Reservoir Dogs', 'word', 'dick',   0.4 ),\n",
       "       ('Reservoir Dogs', 'word', 'dicks',   0.43),\n",
       "       ('Reservoir Dogs', 'word', 'fucked',   0.55), ...,\n",
       "       ('Jackie Brown', 'word', 'fucking', 142.47),\n",
       "       ('Jackie Brown', 'word', 'goddamn', 142.97),\n",
       "       ('Jackie Brown', 'death', '', 143.13)],\n",
       "      dtype=[('movie', '<U32'), ('type', '<U16'), ('word', '<U16'), ('minutes_in', '<f4')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypeTarantino = [\n",
    "    (\"movie\",\"U32\"),\n",
    "    (\"type\",\"U16\"),\t\n",
    "    (\"word\",\"U16\"),\t\n",
    "    (\"minutes_in\", \"f\"),\n",
    "]\n",
    "urlTarntino = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/tarantino/tarantino.csv\"\n",
    "dtTarantino = getNpArrayFromCSV(urlTarntino,dtypeTarantino)\n",
    "dtTarantino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.57446809,  1.20833333, 92.        ,  0.9047619 ,  6.27272727,\n",
       "       67.        , 42.1       ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# задание 4.1 \n",
    "unique_movies = np.unique(dtTarantino['movie'])\n",
    "count_obscene_curr_m = np.array([len(dtTarantino[(dtTarantino['movie']==current_move) & (dtTarantino['type']=='word')]) for current_move in unique_movies])\n",
    "count_death_curr_m = np.array([len(dtTarantino[(dtTarantino['movie']==current_move) & (dtTarantino['type']=='death')]) for current_move in unique_movies])\n",
    "count_obscene_curr_m/count_death_curr_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задание 4.2\n",
    "obscene = dtTarantino[dtTarantino['type']=='word']\n",
    "uniqie_obscene = np.unique(obscene['word'])\n",
    "count_obscene = len(obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count word ass = 0.08215962441314555',\n",
       " 'count word asses = 0.002347417840375587',\n",
       " 'count word asshead = 0.0005868544600938967',\n",
       " 'count word asshole = 0.005868544600938967',\n",
       " 'count word assholes = 0.0029342723004694834',\n",
       " 'count word bastard = 0.005868544600938967',\n",
       " 'count word bastards = 0.0005868544600938967',\n",
       " 'count word bitch = 0.03755868544600939',\n",
       " 'count word bitches = 0.00528169014084507',\n",
       " 'count word bullshit = 0.008802816901408451',\n",
       " 'count word chickenshit = 0.0005868544600938967',\n",
       " 'count word cockblockery = 0.0005868544600938967',\n",
       " 'count word cocksucker = 0.0011737089201877935',\n",
       " 'count word cunt = 0.0011737089201877935',\n",
       " 'count word cunts = 0.0005868544600938967',\n",
       " 'count word damn = 0.02171361502347418',\n",
       " 'count word damned = 0.0017605633802816902',\n",
       " 'count word dick = 0.008215962441314555',\n",
       " 'count word dickless = 0.0005868544600938967',\n",
       " 'count word dicks = 0.0029342723004694834',\n",
       " 'count word dumbass = 0.0005868544600938967',\n",
       " 'count word faggot = 0.0005868544600938967',\n",
       " 'count word fuck = 0.125',\n",
       " 'count word fucked = 0.014671361502347418',\n",
       " 'count word fucker = 0.004694835680751174',\n",
       " 'count word fuckers = 0.0005868544600938967',\n",
       " 'count word fuckface = 0.0005868544600938967',\n",
       " 'count word fuckhead = 0.0005868544600938967',\n",
       " 'count word fucking = 0.23884976525821597',\n",
       " 'count word fucks = 0.0017605633802816902',\n",
       " 'count word fuckup = 0.0005868544600938967',\n",
       " 'count word goddamn = 0.06631455399061033',\n",
       " 'count word goddamned = 0.0005868544600938967',\n",
       " 'count word gook = 0.0005868544600938967',\n",
       " 'count word gooks = 0.0011737089201877935',\n",
       " 'count word hell = 0.02640845070422535',\n",
       " 'count word horeshit = 0.0005868544600938967',\n",
       " 'count word horseshit = 0.0011737089201877935',\n",
       " 'count word jackass = 0.0005868544600938967',\n",
       " 'count word jap = 0.0005868544600938967',\n",
       " 'count word japs = 0.0011737089201877935',\n",
       " 'count word jew (verb) = 0.0005868544600938967',\n",
       " 'count word merde = 0.0005868544600938967',\n",
       " 'count word motherfucker = 0.04107981220657277',\n",
       " 'count word motherfuckers = 0.008802816901408451',\n",
       " 'count word motherfucking = 0.01584507042253521',\n",
       " 'count word n-word  = 0.10504694835680752',\n",
       " 'count word negro  = 0.0029342723004694834',\n",
       " 'count word pussy = 0.006455399061032864',\n",
       " 'count word shit = 0.12969483568075119',\n",
       " 'count word shithead = 0.0017605633802816902',\n",
       " 'count word shitless = 0.0005868544600938967',\n",
       " 'count word shitload = 0.0011737089201877935',\n",
       " 'count word shittiest = 0.0005868544600938967',\n",
       " 'count word shitting = 0.0005868544600938967',\n",
       " 'count word shitty = 0.002347417840375587',\n",
       " 'count word slope = 0.0005868544600938967',\n",
       " 'count word slut = 0.0005868544600938967',\n",
       " 'count word squaw = 0.0005868544600938967',\n",
       " 'count word wetback = 0.0011737089201877935']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"count word {obsc} = {np.count_nonzero(obscene['word'] == obsc)/count_obscene}\" for obsc in uniqie_obscene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232 249 189 159 183 155 118 187 173  59] [  0.4      16.388    32.376    48.364    64.352    80.34     96.328\n",
      " 112.316   128.304   144.29199 160.28   ]\n"
     ]
    }
   ],
   "source": [
    "# задание 4.3\n",
    "word_data = dtTarantino[dtTarantino[\"type\"] == \"word\"]\n",
    "minutes_in_values = word_data[\"minutes_in\"]\n",
    "hist, bin_edges = np.histogram(minutes_in_values)\n",
    "print(hist, bin_edges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
